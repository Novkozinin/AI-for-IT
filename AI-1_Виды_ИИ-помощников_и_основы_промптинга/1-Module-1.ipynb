{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Виды ИИ-помощников и основы промптинга**\n",
    "\n",
    "### <center><span style=color:green>**1/5 Виды ИИ**\n",
    "\n",
    "\n",
    "**Искуственный Интеллект (AI)** - это искуственная интеллектуальная система, которая может выполнять творческие функции, обучаться и творить.\n",
    "\n",
    "**Нейросеть** - это математичекская модель, еоторая работает по образу живых нервных клеток.\n",
    "\n",
    "**Большая Языковая Модель LLM (Large Language Model)** - это языковая модель, состоящая из нейронной сети со множеством параметров и обученная на большом объеме текстов.\n",
    "\n",
    "Типы LLM:\n",
    "- Base LLM (например: Github Copilot)\n",
    "- Instructioned Tuned LLM (например: Chat GPT)\n",
    "\n",
    "### <center><span style=color:green>**2/5 Copilot: как настроить и пользоваться**\n",
    "\n",
    "> **Base LLM** — это LLM (Large Language Model) наученная предсказывать следующее слово в тексте.\n",
    "\n",
    "Прообразом для современных LLM можно назвать систему Т9 для автодополнения текста на первых кнопочных телефонах и последующие системы рекомендаций слов, которые в современных смартфонах работают уже достаточно «умно».\n",
    "\n",
    "Обычно для обучения таких моделей используются большие объемы текстов, что позволяет модели предсказывать следующие слова основываясь на текущем тексте. Таким образом, эти модели хорошо «дописывают» текущий текст новыми словами или целыми абзацами текста. Если же модель научить на большом объеме исходных кодов, то она сможет предсказывать новые куски кода на основе того что уже написано в файле или проекте.\n",
    "\n",
    "Ярким представителем этого типа LLM для разработчиков является модель **Github Copilot**. Copilot научен на огромном количестве публичных репозиториев Github. В настоящее время Copilot доступен для целого ряда IDE (включая VS Studio, IDEA, WebStorm) и поддерживает множество языков программирования и стилей. В большинстве случаев для того чтобы использовать Copilot нужно установить плагин, авторизовать его через Github и оплатить подписку (либо начать триальный период).\n",
    "\n",
    "*Устанавливаем GitHub Copilot в IntelliJ IDEA:*\n",
    "\n",
    "1. Открываем окно Settings → Plugins.\n",
    "2. На вкладке Marketplace вбиваем «Github Copilot».\n",
    "3. Нажимаем кнопку Install.\n",
    "4. После инсталляции необходим рестарт IDE.\n",
    "5. Далее нужно авторизоваться в плагине с помощью Github. На странице Github нужно начать пробный период, либо оплатить подписку.\n",
    "6. После авторизации и оплаты подписки плагин активен и включен.\n",
    "\n",
    "*Использование — написание кода:*\n",
    "\n",
    "1. В любом месте пишем символ, ждем несколько миллисекунд — получаем предложение от Copilot, нажимаем Tab для применения предложения.\n",
    "2. Можно увеличить точность и эффективность предлагаемого кода, если сперва написать подробный комментарий к классу или методу. Поддерживает разные языки, так что комментарий может быть написан и на русском языке.\n",
    "3. Точно так же можно использовать для написания тестов.\n",
    "4. Можно наоборот легко написать комментарий для уже написанного метода или класса.\n",
    "\n",
    "### <center><span style=color:green>**3/5  Instruction Tuned LLM**\n",
    "\n",
    ">**Instruction-Tuned LLM** — это LLM, доработанная под исполнение инструкций. Обучаемые данные для такой модели включают также большой набор пар «инструкция-ответ», на которых модель учится давать ожидаемые ответы. Таким образом, после дообучения такая модель не просто генерирует текст на основе того, что уже есть в контексте, а умеет следовать инструкциям и давать ожидаемые ответы.\n",
    "\n",
    "Одними из самых известных представителей Instruction-Tuned LLM на сегодняшний день являются OpenAI ChatGPT, Google Bard, Microsoft Bing Chat.\n",
    "\n",
    "* Доступ к веб-версии ChatGPT можно получить по ссылке [chat.openai.com](https://chat.openai.com/). После авторизации у вас будет возможность начать использование ChatGPT.\n",
    "\n",
    "*<span style=background-color:yellow;color:black>OpenAI ChatGPT не доступен пользователям из России. Для получения доступа к технологии можно воспользоваться инструкцией из [статьи на Хабре](https://habr.com/ru/articles/704600/).*\n",
    "\n",
    "* Google Bard не доступен в европейских странах, включая Россию.\n",
    "* Microsoft Bing Chat доступен в браузере Edge при открытии окна чата Bing.\n",
    "\n",
    "### <center><span style=color:green>**4/5  Что такое промтинг**\n",
    "\n",
    "> **Промптинг** — это процесс задания начальных условий или стимула для языковых моделей. Грубо говоря, это запрос, аналогичный тому, что мы делаем при поиске в поисковых системах.\n",
    "\n",
    "Основное отличие промпта для языковой модели от запроса к поисковой системе в том, что поисковая система по умолчанию ищет источники, которые содержат заданную поисковую фразу, в то время как языковые модели используют промпт как базу для генерации ответа, основываясь на всей доступной информации, на которой была обучена модель.\n",
    "\n",
    "Выделим важные аспекты промпта для языковой модели:\n",
    "\n",
    "1. **Длина**. При описании задания для языковой модели стоит учитывать, что языковые модели имеют ограниченную длину обрабатываемого контекста. Например, для ChatGPT версии 3 это 2048 токенов, а для ChatGPT версии 4 — 4096 токенов. Токен — это языковая единица. В английском языке это обычно отдельные слова и знаки препинания. В других языках это могут быть более короткие языковые конструкции (вплоть до символов) — в зависимости от особенностей языка.\n",
    "2. **Языковая модель**. Стоит учитывать используемую языковую модель. Если это Base LLM, то промпт служит прообразом для генерируемого текста. Либо можно сказать, что ответ нейросети будет дополнением к тому, что было в промпте. Если же это Instruction-Tuned LLM, то нейросеть попробует выполнить просьбу или дополнить ваш запрос релевантными данными. Т. е. Instruction-Tuned LLM больше похожа на собеседника или помощника.\n",
    "3. **Контекст и детализированность запроса**. Нейросеть отвечает на запрос и использует для ответа весь доступный контекст. Более точный запрос приведет к более точному ответу, тогда как менее точный запрос оставляет больше пространства для свободной интерпретации запроса. В качестве контекста нейросетью также могут использоваться и предыдущие запросы и ответы нейросети. Это стоит учитывать, если вы хотите неожиданно сменить тему запроса и не хотите, чтобы прошлые запросы и ответы влияли на самый последний промпт.\n",
    "4. **Экспериментальность**. В отличие от поисковиков, где выдача по одному запросу зачастую строго ранжирована и фиксирована, нейросеть генерирует свои ответы вероятностно, поэтому различные запуски одного и того же промпта могут приводить к различным ответам. Изменение отдельных деталей промпта также может сильно влиять на выдаваемый нейросетью ответ, поэтому можно экспериментировать с различными промптами и даже запускать несколько раз один и тот же, чтобы добиться наиболее подходящего результата.\n",
    "5. **Язык**. Различные модели обучены на разном количестве текстов на различных языках. Репрезентация языков неравнозначна в обучающей выборке, более того — репрезентация проблем и решений на этих языках может разной. Таким образом, выбор языка промпта может сильно повлиять на качество предоставляемого ответа. В общем случае из-за большей представленности английского языка ответы на английском могут быть точнее, однако если какая-то проблема активнее обсуждается в русскоязычном сообществе и тексты именно этого сообщества попали в обучающую выборку, то именно эта проблема на этом языке может быть обработана нейросетью наилучшим образом.\n",
    "\n",
    "### <center><span style=color:green>**5/5  Принципы и тактики написания промтинга**\n",
    "\n",
    "OpenAI (разработчик ChatGPT) выделяет 2 стратегии и несколько тактик написания качественных промптов для разработчиков.\n",
    "\n",
    "#### Стратегия «Четкие и детализированные инструкции»\n",
    "\n",
    "Instruction-Tuned LLM запрограммирована четко следовать инструкциям, поэтому чем четче и детальнее описаны инструкции, тем более четким и ожидаемым будет ответ.\n",
    "\n",
    "Обычно в коммуникации люди используют интонацию, чтобы разделить разные блоки фраз и инструкций. С ИИ же мы используем только текст, поэтому для разделения различных блоков можно использовать следующие тактики — они помогают повысить степень понимания ИИ и увеличить безопасность и точность запросов в случае интеграции через API:\n",
    "\n",
    "1. Используйте разделители для разделения частей промпта:\n",
    "\n",
    "* тройные символы типа ```’’’```, ```”””```, ```---```\n",
    "* угловые скобки ```< >```\n",
    "* XML-теги: ```<text></text>```, ```<prompt></prompt>```\n",
    "\n",
    "Эта тактика помогает избежать Injection (в переводе с английского — проникновения) в ваш промпт. Выделив какой-то блок текста тремя кавычками и сообщив об этом в промпте, вы избежите ситуации, когда часть обрабатываемого текста ИИ может воспринять как призыв к действию.\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Например, в промпте можно написать: «Обработай текст, обрамленный тройными кавычками». Тогда в случае, если в пользовательском вводе будут какие-либо цитаты в кавычках, ИИ не запутается в том, где именно пользовательский ввод, где ваши промты и что конкретно нужно обрабатывать.*\n",
    "\n",
    "2. Просите структурированный ответ в виде JSON или XML.\n",
    "\n",
    "Эта тактика поможет вам легко распарсить выдачу ответа от ИИ в вашем приложении или другом коде. В некоторых ситуациях выдача структурированного ответа для ИИ также проще, чем написание кастомного текста с ответом на вопрос.\n",
    "\n",
    "3. Просите модель провалидировать входные данные.\n",
    "\n",
    "Если ваш промпт обрабатывает динамические тексты от ваших пользователей, имеет смысл просить модель дополнительно провалидировать входной текст, что удовлетворяет некоторым условиям, прежде чем бросаться выполнять основное задание. Например, если вы хотите вытащить из диалога персональные данные пользователя, то стоит уточнить у самой модели, действительно ли это диалог, чтобы не получить неожиданные невалидные результаты.\n",
    "\n",
    "4. Дайте модели пример правильного ответа.\n",
    "\n",
    "Наличие у модели примера, как (или в каком стиле) нужно обработать тот или иной текст, даст очень много контекста по тому, чего вы от нее хотите, и позволит более точно выдать вам корректный ответ по новому запросу.\n",
    "\n",
    "#### Стратегия «Давайте модели время для размышлений»\n",
    "\n",
    "Модель так устроена, что пытается решить задачи с ходу и сразу, поэтому иногда может ошибаться, особенно если вы просите выполнять задачи, требующие какой-то математики или последовательных вычислений. Тактики этой стратегии:\n",
    "\n",
    "1. Обозначайте для модели несколько шагов для выполнения задания.\n",
    "\n",
    "Чтобы получить более корректный результат, нужно просить модель выполнить задание и вывести результат частями. Наличие решений для промежуточных шагов в тексте приводит к тому, что финальный ответ получается более точным, потому что модель генерирует каждое новое слово не только на основании вашего промпта, но и того, что уже было сгенерировано для ответа на ваш запрос.\n",
    "\n",
    "2. Попросите модель разработать и описать решение задачи, прежде чем выдавать ответ на нее.\n",
    "\n",
    "Этот подход особенно актуален для задач валидации других решений. Например, вместо «вот задача: < >, вот ответ: < >. Правильный ли это ответ?», можно попросить: «Реши эту задачу, сравни ее с таким-то ответом и выдай результат — верный ли это ответ».\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Используя четкие инструкции и давая ИИ время подумать, можно значительно увеличить точность и правильность ответов.*\n",
    "\n",
    "### <center><span style=color:green>**1/6  Поиск и объяснение ошибки**\n",
    "\n",
    "Поиск и исправление ошибок является одним из самых простых способов начать работу с ИИ, более того, использование ИИ в таких, казалось бы, простых вещах все равно позволяет увеличить эффективность работы.\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Если вы столкнулись с непонятной ошибкой в коде, например ваша IDE подсвечивает проблему, но вы не понимаете, в чем дело, достаточно просто скопировать этот кусок кода в ChatGPT и спросить «это код на <язык программирования>, где тут ошибка?»*\n",
    "\n",
    "ChatGPT провалидирует синтаксис и расскажет, где ошибка. Более того, можно сразу попросить исправить ваш код, впрочем, скорее всего, ChatGPT сделает это превентивно.\n",
    "\n",
    "Если при запуске / компиляции вы получаете текст ошибки, то с помощью ИИ можно узнать причину ошибки и попросить исправленный код. Для этого достаточно скопировать кусок кода в ChatGPT и прислать текст самой ошибки. ChatGPT расскажет о проблеме и предложит исправленный вариант.\n",
    "\n",
    "### <center><span style=color:green>**2/6  Валидация**\n",
    "\n",
    "ChatGPT очень удобно использовать для валидации уже написанного. Например, можно отправить в ChatGPT написанный вами большой SQL-запрос и попросить описать, что происходит в этом запросе. То есть это своего рода перевод с SQL-языка на русский язык. Таким образом можно провалидировать, правильно ли вы составили ваш SQL-запрос и не забыли ли чего-то. Обратный вариант более сложен, т. к. в этом случае ИИ необходимо знать структуру вашей базы данных, при переводе же на человеческий язык ИИ может понять необходимую часть структуры из контекста и из самого SQL-запроса.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
