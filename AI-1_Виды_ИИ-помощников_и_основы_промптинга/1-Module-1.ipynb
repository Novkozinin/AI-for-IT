{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**1. Виды ИИ-помощников и основы промптинга**\n",
    "\n",
    "### <span style=color:green>**1.1 Виды ИИ**\n",
    "\n",
    "\n",
    "**Искуственный Интеллект (AI)** - это искуственная интеллектуальная система, которая может выполнять творческие функции, обучаться и творить.\n",
    "\n",
    "**Нейросеть** - это математичекская модель, еоторая работает по образу живых нервных клеток.\n",
    "\n",
    "**Большая Языковая Модель LLM (Large Language Model)** - это языковая модель, состоящая из нейронной сети со множеством параметров и обученная на большом объеме текстов.\n",
    "\n",
    "Типы LLM:\n",
    "- Base LLM (например: Github Copilot)\n",
    "- Instructioned Tuned LLM (например: Chat GPT)\n",
    "\n",
    "### <span style=color:green>**1.2 Copilot: как настроить и пользоваться**\n",
    "\n",
    "> **Base LLM** — это LLM (Large Language Model) наученная предсказывать следующее слово в тексте.\n",
    "\n",
    "Прообразом для современных LLM можно назвать систему Т9 для автодополнения текста на первых кнопочных телефонах и последующие системы рекомендаций слов, которые в современных смартфонах работают уже достаточно «умно».\n",
    "\n",
    "Обычно для обучения таких моделей используются большие объемы текстов, что позволяет модели предсказывать следующие слова основываясь на текущем тексте. Таким образом, эти модели хорошо «дописывают» текущий текст новыми словами или целыми абзацами текста. Если же модель научить на большом объеме исходных кодов, то она сможет предсказывать новые куски кода на основе того что уже написано в файле или проекте.\n",
    "\n",
    "Ярким представителем этого типа LLM для разработчиков является модель **Github Copilot**. Copilot научен на огромном количестве публичных репозиториев Github. В настоящее время Copilot доступен для целого ряда IDE (включая VS Studio, IDEA, WebStorm) и поддерживает множество языков программирования и стилей. В большинстве случаев для того чтобы использовать Copilot нужно установить плагин, авторизовать его через Github и оплатить подписку (либо начать триальный период).\n",
    "\n",
    "*Устанавливаем GitHub Copilot в IntelliJ IDEA:*\n",
    "\n",
    "1. Открываем окно Settings → Plugins.\n",
    "2. На вкладке Marketplace вбиваем «Github Copilot».\n",
    "3. Нажимаем кнопку Install.\n",
    "4. После инсталляции необходим рестарт IDE.\n",
    "5. Далее нужно авторизоваться в плагине с помощью Github. На странице Github нужно начать пробный период, либо оплатить подписку.\n",
    "6. После авторизации и оплаты подписки плагин активен и включен.\n",
    "\n",
    "*Использование — написание кода:*\n",
    "\n",
    "1. В любом месте пишем символ, ждем несколько миллисекунд — получаем предложение от Copilot, нажимаем Tab для применения предложения.\n",
    "2. Можно увеличить точность и эффективность предлагаемого кода, если сперва написать подробный комментарий к классу или методу. Поддерживает разные языки, так что комментарий может быть написан и на русском языке.\n",
    "3. Точно так же можно использовать для написания тестов.\n",
    "4. Можно наоборот легко написать комментарий для уже написанного метода или класса.\n",
    "\n",
    "### <span style=color:green>**1.3  Instruction Tuned LLM**\n",
    "\n",
    ">**Instruction-Tuned LLM** — это LLM, доработанная под исполнение инструкций. Обучаемые данные для такой модели включают также большой набор пар «инструкция-ответ», на которых модель учится давать ожидаемые ответы. Таким образом, после дообучения такая модель не просто генерирует текст на основе того, что уже есть в контексте, а умеет следовать инструкциям и давать ожидаемые ответы.\n",
    "\n",
    "Одними из самых известных представителей Instruction-Tuned LLM на сегодняшний день являются OpenAI ChatGPT, Google Bard, Microsoft Bing Chat.\n",
    "\n",
    "* Доступ к веб-версии ChatGPT можно получить по ссылке [chat.openai.com](https://chat.openai.com/). После авторизации у вас будет возможность начать использование ChatGPT.\n",
    "\n",
    "*<span style=background-color:yellow;color:black>OpenAI ChatGPT не доступен пользователям из России. Для получения доступа к технологии можно воспользоваться инструкцией из [статьи на Хабре](https://habr.com/ru/articles/704600/).*\n",
    "\n",
    "* Google Bard не доступен в европейских странах, включая Россию.\n",
    "* Microsoft Bing Chat доступен в браузере Edge при открытии окна чата Bing.\n",
    "\n",
    "### <span style=color:green>**1.4  Что такое промтинг**\n",
    "\n",
    "> **Промптинг** — это процесс задания начальных условий или стимула для языковых моделей. Грубо говоря, это запрос, аналогичный тому, что мы делаем при поиске в поисковых системах.\n",
    "\n",
    "Основное отличие промпта для языковой модели от запроса к поисковой системе в том, что поисковая система по умолчанию ищет источники, которые содержат заданную поисковую фразу, в то время как языковые модели используют промпт как базу для генерации ответа, основываясь на всей доступной информации, на которой была обучена модель.\n",
    "\n",
    "Выделим важные аспекты промпта для языковой модели:\n",
    "\n",
    "1. **Длина**. При описании задания для языковой модели стоит учитывать, что языковые модели имеют ограниченную длину обрабатываемого контекста. Например, для ChatGPT версии 3 это 2048 токенов, а для ChatGPT версии 4 — 4096 токенов. Токен — это языковая единица. В английском языке это обычно отдельные слова и знаки препинания. В других языках это могут быть более короткие языковые конструкции (вплоть до символов) — в зависимости от особенностей языка.\n",
    "2. **Языковая модель**. Стоит учитывать используемую языковую модель. Если это Base LLM, то промпт служит прообразом для генерируемого текста. Либо можно сказать, что ответ нейросети будет дополнением к тому, что было в промпте. Если же это Instruction-Tuned LLM, то нейросеть попробует выполнить просьбу или дополнить ваш запрос релевантными данными. Т. е. Instruction-Tuned LLM больше похожа на собеседника или помощника.\n",
    "3. **Контекст и детализированность запроса**. Нейросеть отвечает на запрос и использует для ответа весь доступный контекст. Более точный запрос приведет к более точному ответу, тогда как менее точный запрос оставляет больше пространства для свободной интерпретации запроса. В качестве контекста нейросетью также могут использоваться и предыдущие запросы и ответы нейросети. Это стоит учитывать, если вы хотите неожиданно сменить тему запроса и не хотите, чтобы прошлые запросы и ответы влияли на самый последний промпт.\n",
    "4. **Экспериментальность**. В отличие от поисковиков, где выдача по одному запросу зачастую строго ранжирована и фиксирована, нейросеть генерирует свои ответы вероятностно, поэтому различные запуски одного и того же промпта могут приводить к различным ответам. Изменение отдельных деталей промпта также может сильно влиять на выдаваемый нейросетью ответ, поэтому можно экспериментировать с различными промптами и даже запускать несколько раз один и тот же, чтобы добиться наиболее подходящего результата.\n",
    "5. **Язык**. Различные модели обучены на разном количестве текстов на различных языках. Репрезентация языков неравнозначна в обучающей выборке, более того — репрезентация проблем и решений на этих языках может разной. Таким образом, выбор языка промпта может сильно повлиять на качество предоставляемого ответа. В общем случае из-за большей представленности английского языка ответы на английском могут быть точнее, однако если какая-то проблема активнее обсуждается в русскоязычном сообществе и тексты именно этого сообщества попали в обучающую выборку, то именно эта проблема на этом языке может быть обработана нейросетью наилучшим образом.\n",
    "\n",
    "### <span style=color:green>**1.5  Принципы и тактики написания промтинга**\n",
    "\n",
    "OpenAI (разработчик ChatGPT) выделяет 2 стратегии и несколько тактик написания качественных промптов для разработчиков.\n",
    "\n",
    "#### **Стратегия «Четкие и детализированные инструкции»**\n",
    "\n",
    "Instruction-Tuned LLM запрограммирована четко следовать инструкциям, поэтому чем четче и детальнее описаны инструкции, тем более четким и ожидаемым будет ответ.\n",
    "\n",
    "Обычно в коммуникации люди используют интонацию, чтобы разделить разные блоки фраз и инструкций. С ИИ же мы используем только текст, поэтому для разделения различных блоков можно использовать следующие тактики — они помогают повысить степень понимания ИИ и увеличить безопасность и точность запросов в случае интеграции через API:\n",
    "\n",
    "1. Используйте разделители для разделения частей промпта:\n",
    "\n",
    "* тройные символы типа ```’’’```, ```”””```, ```---```\n",
    "* угловые скобки ```< >```\n",
    "* XML-теги: ```<text></text>```, ```<prompt></prompt>```\n",
    "\n",
    "Эта тактика помогает избежать Injection (в переводе с английского — проникновения) в ваш промпт. Выделив какой-то блок текста тремя кавычками и сообщив об этом в промпте, вы избежите ситуации, когда часть обрабатываемого текста ИИ может воспринять как призыв к действию.\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Например, в промпте можно написать: «Обработай текст, обрамленный тройными кавычками». Тогда в случае, если в пользовательском вводе будут какие-либо цитаты в кавычках, ИИ не запутается в том, где именно пользовательский ввод, где ваши промты и что конкретно нужно обрабатывать.*\n",
    "\n",
    "2. Просите структурированный ответ в виде JSON или XML.\n",
    "\n",
    "Эта тактика поможет вам легко распарсить выдачу ответа от ИИ в вашем приложении или другом коде. В некоторых ситуациях выдача структурированного ответа для ИИ также проще, чем написание кастомного текста с ответом на вопрос.\n",
    "\n",
    "3. Просите модель провалидировать входные данные.\n",
    "\n",
    "Если ваш промпт обрабатывает динамические тексты от ваших пользователей, имеет смысл просить модель дополнительно провалидировать входной текст, что удовлетворяет некоторым условиям, прежде чем бросаться выполнять основное задание. Например, если вы хотите вытащить из диалога персональные данные пользователя, то стоит уточнить у самой модели, действительно ли это диалог, чтобы не получить неожиданные невалидные результаты.\n",
    "\n",
    "4. Дайте модели пример правильного ответа.\n",
    "\n",
    "Наличие у модели примера, как (или в каком стиле) нужно обработать тот или иной текст, даст очень много контекста по тому, чего вы от нее хотите, и позволит более точно выдать вам корректный ответ по новому запросу.\n",
    "\n",
    "#### **Стратегия «Давайте модели время для размышлений»**\n",
    "\n",
    "Модель так устроена, что пытается решить задачи с ходу и сразу, поэтому иногда может ошибаться, особенно если вы просите выполнять задачи, требующие какой-то математики или последовательных вычислений. Тактики этой стратегии:\n",
    "\n",
    "1. Обозначайте для модели несколько шагов для выполнения задания.\n",
    "\n",
    "Чтобы получить более корректный результат, нужно просить модель выполнить задание и вывести результат частями. Наличие решений для промежуточных шагов в тексте приводит к тому, что финальный ответ получается более точным, потому что модель генерирует каждое новое слово не только на основании вашего промпта, но и того, что уже было сгенерировано для ответа на ваш запрос.\n",
    "\n",
    "2. Попросите модель разработать и описать решение задачи, прежде чем выдавать ответ на нее.\n",
    "\n",
    "Этот подход особенно актуален для задач валидации других решений. Например, вместо «вот задача: < >, вот ответ: < >. Правильный ли это ответ?», можно попросить: «Реши эту задачу, сравни ее с таким-то ответом и выдай результат — верный ли это ответ».\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Используя четкие инструкции и давая ИИ время подумать, можно значительно увеличить точность и правильность ответов.*\n",
    "\n",
    "## **2. Тактики использования ИИ-помощников для работы с кодом**\n",
    "\n",
    "### <span style=color:green>**2.1  Поиск и объяснение ошибки**\n",
    "\n",
    "Поиск и исправление ошибок является одним из самых простых способов начать работу с ИИ, более того, использование ИИ в таких, казалось бы, простых вещах все равно позволяет увеличить эффективность работы.\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Если вы столкнулись с непонятной ошибкой в коде, например ваша IDE подсвечивает проблему, но вы не понимаете, в чем дело, достаточно просто скопировать этот кусок кода в ChatGPT и спросить «это код на <язык программирования>, где тут ошибка?»*\n",
    "\n",
    "ChatGPT провалидирует синтаксис и расскажет, где ошибка. Более того, можно сразу попросить исправить ваш код, впрочем, скорее всего, ChatGPT сделает это превентивно.\n",
    "\n",
    "Если при запуске / компиляции вы получаете текст ошибки, то с помощью ИИ можно узнать причину ошибки и попросить исправленный код. Для этого достаточно скопировать кусок кода в ChatGPT и прислать текст самой ошибки. ChatGPT расскажет о проблеме и предложит исправленный вариант.\n",
    "\n",
    "### <span style=color:green>**2.2  Валидация**\n",
    "\n",
    "ChatGPT очень удобно использовать для валидации уже написанного. Например, можно отправить в ChatGPT написанный вами большой SQL-запрос и попросить описать, что происходит в этом запросе. То есть это своего рода перевод с SQL-языка на русский язык. Таким образом можно провалидировать, правильно ли вы составили ваш SQL-запрос и не забыли ли чего-то. Обратный вариант более сложен, т. к. в этом случае ИИ необходимо знать структуру вашей базы данных, при переводе же на человеческий язык ИИ может понять необходимую часть структуры из контекста и из самого SQL-запроса.\n",
    "\n",
    "### <span style=color:green>**2.3  Написание тестов для кода**\n",
    "\n",
    "Одной из задач для ChatGPT является написание тестов для определенного кода. Все, что нужно сделать для написания тестов — скопировать файл и попросить написать тесты на все методы либо только на один метод. Разумеется, это работает для юнит-тестов для не слишком нагруженных классов, в противном случае нужно задавать ИИ больше контекста и/или так же отправлять другие файлы.\n",
    "\n",
    "### <span style=color:green>**2.4  Переписывание на другую технологию**\n",
    "\n",
    "Еще одной типовой задачей для LLM является переписывание кода на другую технологию. Это особенно полезно, если вы хорошо разбираетесь в одной технологии и синтаксисе, но слабо знакомы с другой. Тогда вы можете написать нужный вам метод или класс на той технологии, с которой вы более знакомы, а потом попросить ИИ переписать этот класс или метод на интересующую вас технологию.\n",
    "\n",
    "Все, что нужно для этого сделать, ― скопировать нужный текст и попросить переписать в промпте к ИИ.\n",
    "\n",
    "### <span style=color:green>**2.5  Преобразование форматов и составление документов**\n",
    "\n",
    "Еще одной типовой задачей для ChatGPT является преобразование форматов и написание документации.\n",
    "\n",
    "Для преобразования XML в JSON достаточно скопировать структуру в исходном формате и попросить переформатировать в другой формат.\n",
    "\n",
    "Также можно попросить преобразовать какие-то структуры из JSON-описания в табличный markdown-формат для добавления к документации.\n",
    "\n",
    "Либо более сложный вариант: когда у вас есть различные форматы одних и тех же данных и вы хотите визуально их сравнить — можно так же скопировать их всех и попросить выдать сводную таблицу по ним.\n",
    "\n",
    "\n",
    "### <span style=color:green>**2.6  Галлюцинации**\n",
    "\n",
    "Работая с моделями типа ChatGPT, нельзя забывать, что это лишь инструмент, который очень хорошо генерирует текст. Но «генерация» не означает «валидация». Текст генерируется на основе всего объема данных, что есть у ИИ в наличии, но он все равно генерируется, а это означает, что он не существует до генерации и не берется из какого-то источника.\n",
    "\n",
    "> И в этом проявляется один из основных недостатков ИИ на основе нейросетей ― **«галлюцинации»**. Это проявляется в том, что иногда в ответах ИИ появляются несуществующие или неправдивые факты. Разработчики моделей со временем улучшают модели, но до конца избавиться от галлюцинаций все равно не выходит.\n",
    "\n",
    "Самый простой способ обнаружить галлюцинации ― попросить ИИ решить математическую задачку. Текстовому ИИ сложно дается даже несложная математика, поэтому ответы могут быть довольно неточными.\n",
    "\n",
    "Галлюцинации также можно обнаружить, задавая промты на технологии или явления, с которыми ИИ не очень знаком, или информации о которых было мало в обучающей выборке.\n",
    "\n",
    "В самых простых ситуациях ИИ может работать как интерпретатор кода, но из-за отсутствия внутри модели любых классических вычислительных мощностей результат также будет сгенерирован, а не вычислен. И точность результата в этом случае будет ниже 100%.\n",
    "\n",
    "## **3. Продвинутые методы использования: плагины и API**\n",
    "\n",
    "### <span style=color:green>**3.1 Аналитика данных с помощью AI**\n",
    "\n",
    "ChatGPT, хоть и является ИИ общего назначения, имеет ряд существенных недостатков, которые связаны с архитектурой и текстовой природой нейросети. Например, ChatGPT не умеет самостоятельно переходить по ссылкам, заниматься интерпретацией кода, математическими вычислениями или дата-анализом.\n",
    "\n",
    "Для обхода этих недостатков, начиная с версии 4, разработчик ИИ компания OpenAI добавила возможность использовать плагины.\n",
    "\n",
    "> **Плагины** работают как дополнительный посредник между пользователем и ИИ, который дорабатывает промпты для ИИ и предоставляет ему свои возможности.\n",
    "\n",
    "Таким образом, в ChatGPT можно добавить возможности по загрузке данных из сети, калькуляторы, интерпретаторы кода, а также можно создать свой собственный плагин, который предоставит ИИ какой-либо API для того, чтобы ИИ мог использовать его для доступа к real-time данных или даже для выполнения каких-либо операций с вашим продуктом.\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Для доступа к API необходимо переключиться на версию 4, активировать плагины прямо в окне чата и выбрать необходимые вам плагины. На момент написания статьи одновременно можно активировать до 3 плагинов. Таким образом можно расширить возможности ИИ и избежать его недостатков, например отсутствия возможности доступа к real-time данным и галлюцинаций.*\n",
    "\n",
    "Например, для добавления в ИИ функциональности калькулятора можно использовать плагин Calculator, для доступа по ссылкам ― WebPilot, для рисования графиков ― Show Me Diagrams. Сотни других плагинов также доступны в Store в ChatGPT.\n",
    "\n",
    "Актуальные полезные плагины, например, для задач по аналитике данных, всегда можно найти путём простого поиска в интернете — их уже более 1 000 в Store и они обновляются еженедельно.\n",
    "\n",
    "### <span style=color:green>**3.2 Интеграция API**\n",
    "\n",
    "Кроме непосредственно диалога в виде чата ChatGPT также имеет API и позволяет интегрировать его напрямую с другими сервисами. В самом простом варианте через API можно просить ИИ выдавать результат в определенной структуре, например XML или JSON, что позволяет ответ ИИ автоматически обрабатывать вашим сервисом. Использование API ― платная функция, которая оплачивается за каждый сгенерированный ИИ токен (слово или символ).\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Для использования API нужно пройти по ссылке [platform.openai.com](https://platform.openai.com/). Сайт содержит документацию, библиотеки и информацию по балансу аккаунта.*\n",
    "\n",
    "Для доступа к биллинговой информации нужно перейти в пункт меню аккаунта «Manage Account». Здесь содержится информация по использованию ИИ, текущему балансу, лимитам использования по моделям. Обратите внимание что OpenAI, разработчик ChatGPT, предлагает не только модели для работы с текстом, но также и модели для работы с изображениями и аудио.\n",
    "\n",
    "Другие разделы сайта также содержат много полезной информации, например раздел Documentation описывает множество приемов по эффективному использованию ChatGPT.\n",
    "\n",
    "Кстати, использование ChatGPT через API также позволяет использовать некоторые свойства, недоступные в диалоговом режиме, например вы можете задавать температуру ответов ИИ, которая влияет на креативность ответов. Перед непосредственно интеграцией следует заглянуть в этот раздел, потому что разработчики OpenAI постоянно обновляют документацию по мере выхода новых версий моделей.\n",
    "\n",
    "## **4. Личное использование**\n",
    "\n",
    "### <span style=color:green>**4.1 Личные задачи**\n",
    "\n",
    "Несмотря на широкие возможности ChatGPT в качестве помощника в инженерных задачах, основное его предназначение ― это работа с текстом, например:\n",
    "\n",
    "* перевод текстов;\n",
    "* преобразование или редактирование текстов;\n",
    "* написание правильных e-mail;\n",
    "* формулирование мыслей;\n",
    "* личные запросы по любым широкоизвестным темам ― от запросов на научно популярные темы до кухонных рецептов.\n",
    "\n",
    "### <span style=color:green>**4.2 Результаты модуля**\n",
    "\n",
    "В этом модуле мы рассмотрели работу с текстовыми моделями LLM на примере Copilot и ChatGPT. Узнали особенности разных моделей, принципы и тактики в написании промптов, а также выяснили, как ИИ может помогать в работе IT-специалисту уже сегодня.\n",
    "\n",
    "В настоящее время происходит бум в развитии нейросетей. В процессе работы над модулем доступный размер контекста для ChatGPT увеличился с 4000 токенов до 32 000, что может значительно увеличить пул решаемых ИИ задач и увеличить точность их решения. Ежедневно появляются и другие узкоспециализированные решения и плагины для работы нейросетями. Видно, что на 100% заменить человека они не могут, но уже сейчас существенно меняют сам рынок труда и подходы к работе, т. к. очень разнообразно и в неожиданных местах влияют на производительность труда. Тот объем работы, который раньше выполняли несколько сотрудников, с помощью ИИ может делать кратно меньшее количество людей. Но эти люди должны быть профессионалами, т. к. любой результат работы ИИ пока что нужно дополнительно валидировать.\n",
    "\n",
    "*<span style=background-color:lightgreen;color:black>Понимание принципов работы нейросетей и стратегий написания промптов поможет стать именно тем специалистом, который будет требоваться на рынке труда в ближайшие годы.*\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
